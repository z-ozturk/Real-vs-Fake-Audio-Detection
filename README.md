# Real vs. Fake Audio Detection (Chatterbox) ğŸ™ï¸ğŸ¤–

This project is a machine learning-based system designed to distinguish between real human voices and synthetic (deepfake) voices generated using the **Chatterbox TTS** model.

## ğŸš€ Key Features
- **Signal Processing:** Advanced feature extraction using `librosa` (MFCC, Spectral Centroid, ZCR, etc.).
- **Machine Learning:** Classification powered by Support Vector Machines (SVM) with RBF kernel.
- **Accuracy:** Achieved **93.75% accuracy** on the test dataset.
- **Ready to Use:** Automated generation and classification scripts.


## ğŸ“‚ Project Structure
```text
Real-vs-Fake-Audio-Detection/
â”œâ”€â”€ data/               # Dataset (Real & Fake .wav files)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ generator.py    # Generates synthetic samples via Chatterbox
â”‚   â””â”€â”€ classifier.py   # Feature extraction and SVM training
â”œâ”€â”€ reports/            # Project reports and documentation
â””â”€â”€ requirements.txt    # Python dependencies
```
ğŸ› ï¸ Installation & Usage

1. Clone the repository:

```
git clone [https://github.com/z-ozturk/Real-vs-Fake-Audio-Detection.git](https://github.com/z-ozturk/Real-vs-Fake-Audio-Detection.git)
cd Real-vs-Fake-Audio-Detection
```

2. Install dependencies:

```pip install -r requirements.txt```

3. Run the classifier:

```python src/classifier.py```


ğŸ“Š Results & Performance

The model was evaluated using a confusion matrix and standard classification metrics.

Overall Accuracy: 93.75%
Fake Precision: 1.00 (Zero false alarms for real voices)
RBF SVM Parameters: C=15.0, Gamma='scale'

ğŸ‘¥ Contributors
Eda TEKEÅ (eda.t.23@ogr.iu.edu.tr)
Selen GÃœNEL (seleng@ogr.iu.edu.tr)

Zehra Ã–ZTÃœRK (zehraozturk2023@ogr.iu.edu.tr)


